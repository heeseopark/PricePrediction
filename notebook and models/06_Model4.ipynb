{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader, Subset\n",
    "from datetime import datetime as dt, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from pandas import DataFrame as df\n",
    "import mplfinance as mpf\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "seed = 42  # choose any seed you prefer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, item, timespan, start_date_str, end_date_str):\n",
    "        self.directory = f'../csvfiles/{item}'\n",
    "        self.item = item\n",
    "        self.timespan = timespan\n",
    "        start_date = dt.strptime(start_date_str, '%Y-%m-%d').date()\n",
    "        end_date = dt.strptime(end_date_str, '%Y-%m-%d').date()\n",
    "        self.dates = [single_date.strftime(\"%Y-%m-%d\") for single_date in self.daterange(start_date, end_date)]\n",
    "        self.columns = [1, 4]  # Selecting open and close prices\n",
    "        self.filenames = self.get_filenames()\n",
    "\n",
    "    def daterange(self, start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days) + 1):\n",
    "            yield start_date + timedelta(n)\n",
    "\n",
    "    def get_filenames(self):\n",
    "        filenames = []\n",
    "        for date in self.dates:\n",
    "            filename = f\"{self.directory}/{self.item}-{self.timespan}-{date}.csv\"\n",
    "            if os.path.exists(filename):\n",
    "                filenames.append(filename)\n",
    "        return filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        df = pd.read_csv(filename, usecols=self.columns, header=None)\n",
    "        df = df[df.columns[::-1]]  # Swap the columns\n",
    "        df = df.diff(axis=1)[1]  # Compute difference between close and open price for each row\n",
    "        return torch.tensor(df.values, dtype=torch.float32)  # Convert to tensor\n",
    "\n",
    "\n",
    "def sliding_window_fn(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 100 + 1):  # Create windows of 100 rows each\n",
    "            windows.append(tensor[i:i+100])\n",
    "    return torch.stack(windows)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the dataset\n",
    "dataset = PriceDataset('BTCUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "\n",
    "# Shuffle the dataset indices\n",
    "indices = list(range(len(dataset)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Split the indices into training and test sets\n",
    "split_idx = int(0.8 * len(indices))\n",
    "train_indices, test_indices = indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "# Create data subsets using the indices\n",
    "train_data = Subset(dataset, train_indices)\n",
    "test_data = Subset(dataset, test_indices)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=1, collate_fn=sliding_window_fn, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1, collate_fn=sliding_window_fn, shuffle=False, drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.PriceDataset object at 0x000001E06B6A9590>\n",
      "../csvfiles/BTCUSDT\n",
      "<torch.utils.data.dataset.Subset object at 0x000001E06B67AA90>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001E06B6A8790>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset.directory)\n",
    "\n",
    "dataset.__getitem__(2)\n",
    "print(train_data)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=50, output_dim=10, num_layers=4):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape the input tensor to [batch_size, sequence_length, number_of_features]\n",
    "        x = x.view(x.size(0), -1, 1)\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        # LSTM layer\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.to(device)  # Move the data to the device (CPU or GPU)\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(data)  # Forward pass\n",
    "        loss = criterion(outputs, data[:, -10:])  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the weights\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)  # Move the data to the device\n",
    "            outputs = model(data)  # Forward pass\n",
    "            loss = criterion(outputs, data[:, -10:])  # Compute the loss\n",
    "            test_loss += loss.item() * data.size(0)  # Accumulate the loss\n",
    "    return test_loss / len(test_loader.dataset)  # Return the average loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 1160477.852468576\n",
      "Epoch 2, Validation Loss: 651425.2212621656\n",
      "Epoch 3, Validation Loss: 491315.5316675354\n",
      "Epoch 4, Validation Loss: 391165.22806324845\n",
      "Epoch 5, Validation Loss: 334974.6895817113\n",
      "Epoch 6, Validation Loss: 302000.78508094663\n",
      "Epoch 7, Validation Loss: 299456.7030421578\n",
      "Epoch 8, Validation Loss: 253066.7248371487\n",
      "Epoch 9, Validation Loss: 244666.92056701327\n",
      "Epoch 10, Validation Loss: 214385.18947878986\n",
      "Epoch 11, Validation Loss: 205792.18721823048\n",
      "Epoch 12, Validation Loss: 214868.07253340355\n",
      "Epoch 13, Validation Loss: 174372.7991829162\n",
      "Epoch 14, Validation Loss: 184788.7712083695\n",
      "Epoch 15, Validation Loss: 170871.8635989463\n",
      "Epoch 16, Validation Loss: 170303.79280305744\n",
      "Epoch 17, Validation Loss: 148985.1409515787\n",
      "Epoch 18, Validation Loss: 162340.04853080053\n",
      "Epoch 19, Validation Loss: 148123.20780297308\n",
      "Epoch 20, Validation Loss: 156218.70617380983\n",
      "Epoch 21, Validation Loss: 193870.04679233866\n",
      "Epoch 22, Validation Loss: 166638.30160110403\n",
      "Epoch 23, Validation Loss: 189799.86998710092\n",
      "Epoch 24, Validation Loss: 175717.8156192033\n",
      "Epoch 25, Validation Loss: 163844.92479304623\n",
      "Epoch 26, Validation Loss: 156016.07388693688\n",
      "Epoch 27, Validation Loss: 137455.84971328088\n",
      "Epoch 28, Validation Loss: 122087.22373814927\n",
      "Epoch 29, Validation Loss: 181177.24810047157\n",
      "Epoch 30, Validation Loss: 184399.64552748165\n"
     ]
    }
   ],
   "source": [
    "# Create the model, criterion, and optimizer\n",
    "model = LSTM().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 30\n",
    "\n",
    "# Train and evaluate the model\n",
    "for epoch in range(epochs):  # Adjust the number of epochs as needed\n",
    "    train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Validation Loss: {val_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
