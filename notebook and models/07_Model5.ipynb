{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader, Subset\n",
    "from datetime import datetime as dt, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from pandas import DataFrame as df\n",
    "import mplfinance as mpf\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "seed = 42  # choose any seed you prefer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, item, timespan, start_date_str, end_date_str):\n",
    "        self.directory = f'../csvfiles/{item}'\n",
    "        self.item = item\n",
    "        self.timespan = timespan\n",
    "        start_date = dt.strptime(start_date_str, '%Y-%m-%d').date()\n",
    "        end_date = dt.strptime(end_date_str, '%Y-%m-%d').date()\n",
    "        self.dates = [single_date.strftime(\"%Y-%m-%d\") for single_date in self.daterange(start_date, end_date)]\n",
    "        self.columns = [1, 4]  # Selecting open and close prices\n",
    "        self.filenames = self.get_filenames()\n",
    "\n",
    "    def daterange(self, start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days) + 1):\n",
    "            yield start_date + timedelta(n)\n",
    "\n",
    "    def get_filenames(self):\n",
    "        filenames = []\n",
    "        for date in self.dates:\n",
    "            filename = f\"{self.directory}/{self.item}-{self.timespan}-{date}.csv\"\n",
    "            if os.path.exists(filename):\n",
    "                filenames.append(filename)\n",
    "        return filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        df = pd.read_csv(filename, usecols=self.columns, header=None)\n",
    "        df = df[df.columns[::-1]]  # Swap the columns\n",
    "        df = df.diff(axis=1)[1]  # Compute difference between close and open price for each row\n",
    "        return torch.tensor(df.values, dtype=torch.float32)  # Convert to tensor\n",
    "\n",
    "\n",
    "def sliding_window_fn(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 100 + 1):  # Create windows of 100 rows each\n",
    "            windows.append(tensor[i:i+100])\n",
    "    return torch.stack(windows)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the dataset\n",
    "dataset = PriceDataset('BTCUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "\n",
    "# Shuffle the dataset indices\n",
    "indices = list(range(len(dataset)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Split the indices into training and test sets\n",
    "split_idx = int(0.8 * len(indices))\n",
    "train_indices, test_indices = indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "# Create data subsets using the indices\n",
    "train_data = Subset(dataset, train_indices)\n",
    "test_data = Subset(dataset, test_indices)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=1, collate_fn=sliding_window_fn, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1, collate_fn=sliding_window_fn, shuffle=False, drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)\n",
    "print(dataset.directory)\n",
    "\n",
    "dataset.__getitem__(2)\n",
    "print(train_data)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=50, output_dim=10, num_layers=5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape the input tensor to [batch_size, sequence_length, number_of_features]\n",
    "        x = x.view(x.size(0), -1, 1)\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        # LSTM layer\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.to(device)  # Move the data to the device (CPU or GPU)\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(data)  # Forward pass\n",
    "        loss = criterion(outputs, data[:, -10:])  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the weights\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)  # Move the data to the device\n",
    "            outputs = model(data)  # Forward pass\n",
    "            loss = criterion(outputs, data[:, -10:])  # Compute the loss\n",
    "            test_loss += loss.item() * data.size(0)  # Accumulate the loss\n",
    "    return test_loss / len(test_loader.dataset)  # Return the average loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model, criterion, and optimizer\n",
    "model = LSTM().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 40\n",
    "\n",
    "# Train and evaluate the model\n",
    "for epoch in range(epochs):  # Adjust the number of epochs as needed\n",
    "    train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Validation Loss: {val_loss}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop out 추가하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
