{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader, Subset\n",
    "from datetime import datetime as dt, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from pandas import DataFrame as df\n",
    "import mplfinance as mpf\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "seed = 42  # choose any seed you prefer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, item, timespan, start_date_str, end_date_str):\n",
    "        self.directory = f'C:/Github/PricePrediction/csvfiles/{item}'\n",
    "        self.item = item\n",
    "        self.timespan = timespan\n",
    "        start_date = dt.strptime(start_date_str, '%Y-%m-%d').date()\n",
    "        end_date = dt.strptime(end_date_str, '%Y-%m-%d').date()\n",
    "        self.dates = [single_date.strftime(\"%Y-%m-%d\") for single_date in self.daterange(start_date, end_date)]\n",
    "        self.columns = [1, 4]  # Selecting open and close prices\n",
    "        self.filenames = self.get_filenames()\n",
    "\n",
    "    def daterange(self, start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days) + 1):\n",
    "            yield start_date + timedelta(n)\n",
    "\n",
    "    def get_filenames(self):\n",
    "        filenames = []\n",
    "        for date in self.dates:\n",
    "            filename = f\"{self.directory}/{self.item}-{self.timespan}-{date}.csv\"\n",
    "            if os.path.exists(filename):\n",
    "                filenames.append(filename)\n",
    "        return filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        df = pd.read_csv(filename, usecols=self.columns, header=None)\n",
    "        return torch.tensor(df.values, dtype=torch.float32)  # Return open and close prices\n",
    "\n",
    "def sliding_window_pct(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 100 + 1):  # Create windows of size window_size\n",
    "            window = tensor[i:i+100]\n",
    "            pct_change = (window[:, 1] - window[:, 0]) * 100 / window[:, 0]\n",
    "            windows.append(pct_change)\n",
    "    return torch.stack(windows)\n",
    "\n",
    "def sliding_window_binary(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 100 + 1):  # Create windows of size window_size\n",
    "            window = tensor[i:i+100]\n",
    "            binary_change = (window[:, 1] > window[:, 0]).float()  # Calculate the binary change\n",
    "            windows.append(binary_change)\n",
    "    return torch.stack(windows)\n",
    "\n",
    "def sliding_window_combined(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 100 + 1):  # Create windows of size window_size\n",
    "            window = tensor[i:i+100]\n",
    "            pct_change = (window[:, 1] - window[:, 0]) * 100 / window[:, 0]\n",
    "            binary_change = (window[:, 1] > window[:, 0]).float()  # Calculate the binary change\n",
    "            combined = torch.stack([pct_change, binary_change], dim=-1)  # Stack along a new last dimension\n",
    "            windows.append(combined)\n",
    "    return torch.stack(windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PriceDataset('BTCUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, collate_fn=sliding_window_combined, shuffle=False, drop_last=True)\n",
    "\n",
    "test_dataset = PriceDataset('ETHUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=sliding_window_combined, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 791\n",
      "Test dataset size: 791\n",
      "Train dataloader size: 791\n",
      "Test dataloader size: 791\n",
      "Shape of the tensor output by train_dataset: torch.Size([1440, 2])\n",
      "Shape of the tensor output by train_loader: torch.Size([1341, 100, 2])\n"
     ]
    }
   ],
   "source": [
    "# Size of the Dataset\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Test dataset size: {len(test_dataset)}')\n",
    "\n",
    "# Size of the DataLoader (i.e., number of batches)\n",
    "print(f'Train dataloader size: {len(train_loader)}')\n",
    "print(f'Test dataloader size: {len(test_loader)}')\n",
    "\n",
    "# Size of the tensor output by the Dataset\n",
    "sample_tensor = train_dataset[0]\n",
    "print(f'Shape of the tensor output by train_dataset: {sample_tensor.shape}')\n",
    "\n",
    "# Size of the tensor output by the DataLoader\n",
    "for batch in train_loader:\n",
    "    print(f'Shape of the tensor output by train_loader: {batch.shape}')\n",
    "    break  # we break after the first batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceChangePrediction(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=100, num_layers=4):\n",
    "        super(PriceChangePrediction, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.1)\n",
    "        self.fc_pct = nn.Linear(hidden_dim, 1)  # output layer for percentage prediction\n",
    "        self.fc_binary = nn.Linear(hidden_dim, 1)  # output layer for binary prediction\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out_pct = self.fc_pct(out)  # output for percentage prediction\n",
    "        out_binary = torch.sigmoid(self.fc_binary(out))  # output for binary prediction\n",
    "        return out_pct, out_binary, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ... (your data loading code here) ...\n",
    "\n",
    "# Note: Now you need only one DataLoader. Here I assume we continue to use `train_loader_pct`\n",
    "# and `test_loader_pct`, but you could use `train_loader_binary` and `test_loader_binary` instead.\n",
    "# The critical point is that the data is the same, just the interpretation (and thus the loss) differs.\n",
    "\n",
    "# Create the model\n",
    "model = PriceChangePrediction().to(device)\n",
    "\n",
    "# Define the loss functions\n",
    "percentage_criterion = nn.MSELoss()\n",
    "binary_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define a function to calculate the combined loss\n",
    "def combined_loss(percentage_output, binary_output, percentage_target, binary_target):\n",
    "    percentage_loss = percentage_criterion(percentage_output, percentage_target)\n",
    "    binary_loss = binary_criterion(binary_output, binary_target)\n",
    "    return percentage_loss + binary_loss\n",
    "\n",
    "# Define the training function\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_batches = len(train_loader)  # Total number of batches\n",
    "    for i, batch in enumerate(train_loader):  # Use enumerate to get the index (i)\n",
    "        batch = batch.unsqueeze(-1).to(device)\n",
    "        inputs = batch[:, :-1, :]\n",
    "        percentage_targets = batch[:, 1:, :]\n",
    "        binary_targets = (percentage_targets > 0).float()  # Calculate binary targets\n",
    "        optimizer.zero_grad()\n",
    "        percentage_outputs, binary_outputs = model(inputs)  # Get the two outputs\n",
    "        loss = criterion(percentage_outputs, binary_outputs, percentage_targets, binary_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i + 1) % 200 == 0:  # Print after every 200 batches\n",
    "            print(f\"Training progress: [{i + 1}/{total_batches} Batches]\")\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.unsqueeze(-1).to(device)\n",
    "            inputs = batch[:, :-1, :]\n",
    "            percentage_targets = batch[:, 1:, :]\n",
    "            binary_targets = (percentage_targets > 0).float()  # Calculate binary targets\n",
    "            percentage_outputs, binary_outputs = model(inputs)  # Get the two outputs\n",
    "            loss = criterion(percentage_outputs, binary_outputs, percentage_targets, binary_targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)  # Return average loss\n",
    "\n",
    "# ... (your training loop here) ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
