{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader, Subset\n",
    "from datetime import datetime as dt, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from pandas import DataFrame as df\n",
    "import mplfinance as mpf\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "seed = 42  # choose any seed you prefer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, item, timespan, start_date_str, end_date_str):\n",
    "        self.directory = f'../csvfiles/{item}'\n",
    "        self.item = item\n",
    "        self.timespan = timespan\n",
    "        start_date = dt.strptime(start_date_str, '%Y-%m-%d').date()\n",
    "        end_date = dt.strptime(end_date_str, '%Y-%m-%d').date()\n",
    "        self.dates = [single_date.strftime(\"%Y-%m-%d\") for single_date in self.daterange(start_date, end_date)]\n",
    "        self.columns = [1, 4]  # Selecting open and close prices\n",
    "        self.filenames = self.get_filenames()\n",
    "\n",
    "    def daterange(self, start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days) + 1):\n",
    "            yield start_date + timedelta(n)\n",
    "\n",
    "    def get_filenames(self):\n",
    "        filenames = []\n",
    "        for date in self.dates:\n",
    "            filename = f\"{self.directory}/{self.item}-{self.timespan}-{date}.csv\"\n",
    "            if os.path.exists(filename):\n",
    "                filenames.append(filename)\n",
    "        return filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        df = pd.read_csv(filename, usecols=self.columns, header=None)\n",
    "        return torch.tensor(df.values, dtype=torch.float32)  # Return open and close prices\n",
    "\n",
    "\n",
    "def sliding_window_pct(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 400 + 1):  # Create windows of 100 rows each\n",
    "            window = tensor[i:i+400]\n",
    "            # Calculate the percentage change for each pair in the window\n",
    "            pct_change = (window[:, 1] - window[:, 0]) * 100 / window[:, 0]\n",
    "            windows.append(pct_change)\n",
    "    # Only keep the first 100 windows if there are more than 100\n",
    "    return torch.stack(windows)\n",
    "\n",
    "def sliding_window_binary(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 400 + 1):  # Create windows of 100 rows each\n",
    "            window = tensor[i:i+400]\n",
    "            binary_change = (window[:, 1] > window[:, 0]).float()  # Calculate the binary change\n",
    "            windows.append(binary_change)\n",
    "    # Only keep the first 100 windows if there are more than 100\n",
    "    return torch.stack(windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "train_dataset = PriceDataset('BTCUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "train_loader_pct = DataLoader(train_dataset, batch_size=1, collate_fn=sliding_window_pct, shuffle=False, drop_last=True)\n",
    "train_loader_binary = DataLoader(train_dataset, batch_size=1, collate_fn=sliding_window_binary, shuffle=False, drop_last=True)\n",
    "\n",
    "test_dataset = PriceDataset('ETHUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "test_loader_pct = DataLoader(test_dataset, batch_size=1, collate_fn=sliding_window_pct, shuffle=False, drop_last=True)\n",
    "test_loader_binary = DataLoader(test_dataset, batch_size=1, collate_fn=sliding_window_binary, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 791\n",
      "Test dataset size: 791\n",
      "Train dataloader size: 791\n",
      "Test dataloader size: 791\n",
      "Shape of the tensor output by train_dataset: torch.Size([1440, 2])\n",
      "Shape of the tensor output by train_loader: torch.Size([941, 500])\n",
      "tensor([ 2.8056e-01,  2.2834e-01, -5.0143e-01, -2.0211e-01, -9.1939e-03,\n",
      "        -1.4603e-01,  3.4472e-02,  1.3322e-01,  4.6631e-01,  3.0887e-02,\n",
      "        -1.6091e-01,  1.4937e-01,  3.2405e-02, -4.9789e-02,  4.7234e-01,\n",
      "         2.6495e-01,  5.9878e-01,  6.2401e-01, -8.1065e-03,  1.9066e-02,\n",
      "         7.1394e-02, -1.7840e-01,  4.7845e-02, -1.7791e-01,  2.7748e-01,\n",
      "        -5.2244e-02,  8.0417e-03,  2.0064e-02, -3.8876e-02,  3.8866e-02,\n",
      "         4.9639e-01, -3.5896e-02,  9.8013e-02,  2.6715e-01, -1.0436e-01,\n",
      "        -1.1240e-01, -7.0540e-02, -9.4212e-02,  4.2307e-02,  1.2704e-01,\n",
      "        -3.0736e-02, -4.9750e-02,  1.0694e-02, -1.5194e-01, -1.7663e-01,\n",
      "        -1.4057e-02, -1.3757e-01,  5.6558e-02, -7.6856e-02,  5.1975e-02,\n",
      "        -8.3747e-04,  6.6676e-02,  2.7647e-01, -1.5278e-01,  1.3293e-01,\n",
      "        -1.3759e-01, -1.0880e-01,  3.8478e-02, -6.5335e-02,  2.9261e-02,\n",
      "         1.1104e-01, -1.3705e-01, -6.8589e-02, -2.0558e-03, -1.2900e-01,\n",
      "        -4.1508e-04,  2.7178e-02, -3.5664e-02,  5.3418e-02, -1.8494e-02,\n",
      "        -5.3923e-02, -8.8969e-02,  6.8707e-02, -2.0595e-01,  1.1608e-01,\n",
      "         1.9656e-01, -5.7029e-02, -5.4223e-02,  1.0866e-01, -1.9230e-02,\n",
      "        -4.1581e-01, -8.8526e-02,  1.9080e-01,  2.1919e-01,  1.0935e-01,\n",
      "        -1.2261e-01, -5.0807e-02,  1.1368e-01,  3.2056e-02, -4.0144e-02,\n",
      "         3.7450e-01,  3.9052e-01, -2.3013e-01, -9.2982e-02, -1.3107e-01,\n",
      "        -1.1971e-01,  1.3795e-01, -2.0743e-01, -7.7665e-02,  1.1093e-01,\n",
      "        -1.0819e-01,  9.1701e-02,  7.4040e-02, -8.7424e-02,  1.2050e-01,\n",
      "         1.4065e-01, -1.1846e-01,  1.3335e-01,  1.2321e-01, -1.5703e-01,\n",
      "         1.6421e-02, -2.3800e-02,  8.7038e-02, -7.5528e-02, -8.6386e-02,\n",
      "        -3.1319e-01, -7.3029e-02,  1.9114e-01, -4.9042e-02,  4.1414e-02,\n",
      "         7.5077e-02, -1.3175e-01,  3.0314e-01,  7.3852e-02, -8.1364e-02,\n",
      "        -5.4028e-03,  9.1323e-02,  5.0639e-02, -1.1372e-01,  1.7203e-02,\n",
      "         1.6325e-01, -1.7912e-01,  1.3893e-01,  6.6937e-02,  3.5304e-02,\n",
      "         1.0976e-01, -2.4577e-01, -1.1721e-02, -7.8391e-02,  4.8270e-02,\n",
      "         2.1121e-01,  1.5195e-02, -2.6633e-02,  1.8248e-01,  3.8161e-01,\n",
      "        -4.8727e-03,  2.3605e-01,  4.3820e-02, -2.3516e-01, -5.3533e-02,\n",
      "         2.0826e-01,  1.0904e-02, -9.6413e-03, -3.2586e-04, -1.8417e-01,\n",
      "        -5.0761e-02, -1.0854e-02, -3.6133e-02, -3.5970e-02, -5.9695e-02,\n",
      "         1.2083e-01, -1.2545e-01,  1.1690e-01, -6.1325e-02, -7.1152e-02,\n",
      "        -1.3802e-01,  3.9945e-02,  4.3993e-02, -9.2117e-02,  4.8676e-02,\n",
      "         1.0182e-01, -2.9481e-02, -9.4398e-02, -1.6484e-02, -8.9699e-02,\n",
      "        -1.5557e-01,  1.7695e-01, -1.0160e-01, -2.3546e-02,  2.5210e-02,\n",
      "         1.1420e-02,  9.4004e-02,  4.2616e-02,  7.4354e-02, -1.8823e-01,\n",
      "        -2.0695e-01,  6.9039e-02, -2.6181e-01,  1.8177e-01, -4.4704e-02,\n",
      "         4.4977e-02, -1.8802e-02,  9.3718e-02, -2.7264e-02,  8.2567e-02,\n",
      "         7.1266e-02,  2.3999e-02,  8.2789e-02,  4.7287e-02, -2.2258e-02,\n",
      "        -6.0834e-02, -5.1084e-02, -9.1017e-02,  4.4659e-02,  3.9724e-02,\n",
      "         7.3447e-02,  4.7130e-02,  1.8579e-02,  6.6624e-03,  1.7718e-02,\n",
      "        -2.0772e-02, -8.1063e-02, -6.8424e-02,  8.4945e-02, -1.3556e-01,\n",
      "         8.7757e-02, -9.8379e-02, -6.7056e-02, -5.9132e-02, -2.0223e-02,\n",
      "        -4.4289e-02, -1.0510e-01,  1.2740e-01,  5.2544e-03,  2.2813e-02,\n",
      "        -1.8559e-01,  1.3573e-01, -1.9807e-02,  7.6272e-03,  9.4237e-02,\n",
      "         5.6337e-02, -3.2221e-02, -1.4816e-01,  1.8904e-01,  5.9754e-02,\n",
      "         2.7307e-01, -3.4776e-01, -8.3771e-02,  6.3207e-02, -4.1047e-02,\n",
      "         1.7043e-01, -6.3201e-03,  4.7671e-02,  1.1649e-01, -6.9435e-02,\n",
      "        -3.7845e-03, -9.2165e-02,  9.8152e-02,  5.6356e-04, -3.5808e-02,\n",
      "         4.2628e-02,  3.5405e-02, -1.0260e-01, -9.4685e-02, -8.4311e-02,\n",
      "         6.7691e-02, -1.5000e-01, -3.6250e-02, -8.5704e-02, -2.7680e-01,\n",
      "        -4.3637e-02, -7.5602e-02, -1.6704e-01,  1.5332e-01,  2.3916e-02,\n",
      "        -5.5929e-02,  5.9702e-02,  9.0278e-02,  1.0700e-01,  2.8515e-02,\n",
      "        -9.9234e-02,  5.3643e-02, -7.5715e-02,  9.9884e-02,  5.8391e-04,\n",
      "        -2.2510e-02, -8.4897e-02, -4.8406e-02,  2.3410e-02,  1.1211e-02,\n",
      "        -5.6979e-02, -4.0625e-02,  1.0029e-01,  2.5902e-01,  7.9032e-02,\n",
      "         6.1456e-02,  1.4898e-01,  3.8169e-03,  3.2674e-02,  6.7079e-02,\n",
      "         4.4955e-01, -1.7743e-01, -8.2525e-02,  4.3207e-02, -1.9546e-01,\n",
      "         2.1995e-02,  8.9593e-02, -1.2136e-01,  2.3933e-02,  6.5474e-02,\n",
      "        -1.7012e-01, -4.5042e-03,  1.6303e-01, -1.9731e-01, -1.6592e-03,\n",
      "        -6.2764e-02, -2.3600e-04, -2.7064e-02, -2.0461e-02,  2.3231e-02,\n",
      "         1.5891e-01, -2.2256e-01,  2.3757e-02,  3.9641e-02, -2.9458e-02,\n",
      "        -5.1233e-02, -1.2349e-01,  5.0174e-02,  4.0573e-02, -1.2722e-01,\n",
      "         3.2495e-02, -5.8092e-02,  6.1000e-02,  7.1591e-02,  1.2604e-02,\n",
      "        -9.2102e-02,  4.1315e-03, -1.1330e-02, -1.4748e-01, -2.5757e-01,\n",
      "         1.5185e-01,  5.7431e-02,  1.0640e-01, -4.7813e-02,  2.6368e-02,\n",
      "         6.0399e-03, -1.0841e-01, -1.6411e-02,  1.3883e-01, -7.1297e-02,\n",
      "        -1.1121e-01,  1.0477e-01, -7.3529e-02,  3.3153e-02, -1.5369e-02,\n",
      "         5.3159e-02, -6.8257e-02, -8.0687e-02, -4.4157e-02,  1.2898e-01,\n",
      "         1.7518e-02, -3.7665e-02, -3.3835e-02,  3.7263e-02, -1.4015e-02,\n",
      "         1.3802e-01,  2.5846e-02,  1.6921e-05,  5.9046e-02,  6.2740e-03,\n",
      "         2.3826e-02, -1.1057e-02, -1.2438e-01, -1.8895e-01,  1.2815e-01,\n",
      "        -2.7050e-02,  7.1820e-02, -2.5818e-03,  2.4395e-02,  7.5019e-02,\n",
      "         4.0242e-02,  4.6287e-02, -2.8751e-02, -8.7968e-02,  1.2382e-01,\n",
      "         3.1721e-02, -6.7046e-02,  8.0240e-02, -1.4246e-02, -3.2238e-02,\n",
      "        -3.4690e-02, -1.3334e-01, -1.5555e-02,  1.0572e-02,  2.7387e-02,\n",
      "         1.0611e-01, -4.0063e-03,  2.4563e-02, -4.7178e-02,  7.6288e-02,\n",
      "         5.4925e-02, -1.0125e-01, -5.1756e-02, -5.6975e-02, -1.0591e-01,\n",
      "        -2.5220e-01,  5.1084e-02, -2.4960e-02, -2.8473e-02, -1.7969e-01,\n",
      "         1.4990e-02, -2.4345e-02, -2.5464e-01,  3.0179e-02, -1.4838e-03,\n",
      "         2.1319e-03, -1.1033e-01, -8.7877e-02, -1.2238e-01, -5.4916e-02,\n",
      "         2.1654e-01,  1.4805e-01,  9.2626e-02, -1.8189e-02, -4.8017e-02,\n",
      "         1.1432e-01, -6.2410e-02, -5.3494e-02,  6.0564e-02,  2.3039e-02,\n",
      "         1.0358e-01,  2.8451e-01,  1.3401e-01,  1.1681e-01, -5.8209e-02,\n",
      "        -5.5863e-02, -1.5727e-01, -3.5870e-02, -6.9721e-02,  1.3954e-01,\n",
      "         8.9493e-03,  9.5253e-02, -8.2502e-02, -4.9957e-03,  2.5623e-01,\n",
      "         5.1270e-02, -9.7151e-02, -9.0039e-02,  1.4721e-01, -4.5518e-03,\n",
      "        -6.3440e-02, -2.8091e-02, -6.3661e-02,  7.2329e-02, -8.7147e-02,\n",
      "         6.4814e-02,  5.9410e-02, -4.7353e-02,  1.7387e-02, -1.9789e-02,\n",
      "         2.5645e-02, -1.7852e-01, -8.9919e-02, -1.0990e-01, -4.1157e-02,\n",
      "         1.6837e-01,  6.5663e-02,  6.2813e-02, -9.3329e-02,  1.0006e-01,\n",
      "        -5.4411e-02,  7.4030e-03, -6.3756e-02,  6.1769e-02,  4.3744e-02,\n",
      "        -5.6455e-02, -3.3607e-02, -1.5247e-01, -5.3290e-02, -1.6058e-02,\n",
      "         1.6958e-01,  6.7207e-02,  7.6110e-02, -8.1919e-02,  1.3586e-01,\n",
      "         2.8919e-01,  1.8368e-01,  5.1870e-02, -1.4419e-01,  2.4504e-02,\n",
      "         4.1820e-02,  2.5423e-01,  1.2427e-02, -2.9397e-02, -7.3321e-02,\n",
      "        -2.0480e-02,  1.8857e-01, -9.7300e-02,  1.4423e-01,  1.6616e-01,\n",
      "         1.7379e-01, -1.1257e-01, -2.6361e-02, -6.7950e-02, -1.6500e-02,\n",
      "        -7.8802e-02,  7.8125e-02,  6.4209e-03, -3.8850e-02,  1.5905e-01])\n"
     ]
    }
   ],
   "source": [
    "# Size of the Dataset\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Test dataset size: {len(test_dataset)}')\n",
    "\n",
    "# Size of the DataLoader (i.e., number of batches)\n",
    "print(f'Train dataloader size: {len(train_loader_binary)}')\n",
    "print(f'Test dataloader size: {len(test_loader_binary)}')\n",
    "\n",
    "# Size of the tensor output by the Dataset\n",
    "sample_tensor = train_dataset[0]\n",
    "print(f'Shape of the tensor output by train_dataset: {sample_tensor.shape}')\n",
    "\n",
    "# Size of the tensor output by the DataLoader\n",
    "for batch in train_loader_binary:\n",
    "    print(f'Shape of the tensor output by train_loader: {batch.shape}')\n",
    "    break  # we break after the first batch\n",
    "\n",
    "first_batch = next(iter(train_loader_binary))\n",
    "\n",
    "first_batch = next(iter(train_loader_pct))\n",
    "print(first_batch[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceChangePrediction(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=100, output_dim=1, num_layers=4):\n",
    "        super(PriceChangePrediction, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout = 0.1)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        batch = batch.unsqueeze(-1).to(device)  # Adds an extra dimension\n",
    "        inputs = batch[:, :-1, :]\n",
    "        targets = batch[:, 1:, :]  # The targets are the next time-steps\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.unsqueeze(-1).to(device)  # Adds an extra dimension\n",
    "            inputs = batch[:, :-1, :]\n",
    "            targets = batch[:, 1:, :]  # The targets are the next time-steps\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)  # Return average loss\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, model_name, train_loader, test_loader, criterion, optimizer, epochs, device):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} \\t | \\t {model_name} \\t | \\t Validation Loss: {val_loss:.10f}\")\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if val_loss < best_val_loss:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'models/{model_name}.pth')\n",
    "            best_val_loss = val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.04 GiB (GPU 0; 8.00 GiB total capacity; 3.91 GiB already allocated; 1.20 GiB free; 4.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[39m# Train and evaluate PriceChangePrediction model\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m train_and_evaluate(percentage_model, \u001b[39m'\u001b[39;49m\u001b[39mpercentage_model\u001b[39;49m\u001b[39m'\u001b[39;49m, train_loader_pct, test_loader_pct, percentage_criterion, percentage_optimizer, epochs, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     32\u001b[0m \u001b[39m# Train and evaluate PriceDirectionPrediction model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m train_and_evaluate(binary_model, \u001b[39m'\u001b[39m\u001b[39mbinary_model\u001b[39m\u001b[39m'\u001b[39m, train_loader_binary, test_loader_binary, binary_criterion, binary_optimizer, epochs, device\u001b[39m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[68], line 32\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, model_name, train_loader, test_loader, criterion, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m best_val_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m---> 32\u001b[0m     train(model, train_loader, criterion, optimizer, device)\n\u001b[0;32m     33\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[0;32m     34\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m Validation Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.10f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[68], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m targets \u001b[39m=\u001b[39m batch[:, \u001b[39m1\u001b[39m:, :]  \u001b[39m# The targets are the next time-steps\u001b[39;00m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 8\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m      9\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     10\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[67], line 8\u001b[0m, in \u001b[0;36mPriceChangePrediction.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m----> 8\u001b[0m     out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[0;32m      9\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out)\n\u001b[0;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.04 GiB (GPU 0; 8.00 GiB total capacity; 3.91 GiB already allocated; 1.20 GiB free; 4.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Create the models\n",
    "percentage_model = PriceChangePrediction().to(device)\n",
    "binary_model = PriceChangePrediction().to(device)\n",
    "\n",
    "# Define the loss functions\n",
    "percentage_criterion = nn.MSELoss()\n",
    "binary_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the optimizers\n",
    "percentage_optimizer = torch.optim.Adam(percentage_model.parameters(), lr=0.01)\n",
    "binary_optimizer = torch.optim.Adam(binary_model.parameters(), lr=0.01)\n",
    "\n",
    "try: \n",
    "    # Load the saved models and optimizers\n",
    "    percentage_checkpoint = torch.load('models/percentage_model.pth')\n",
    "    binary_checkpoint = torch.load('models/binary_model.pth')\n",
    "\n",
    "    percentage_model.load_state_dict(percentage_checkpoint['model_state_dict'])\n",
    "    binary_model.load_state_dict(binary_checkpoint['model_state_dict'])\n",
    "\n",
    "    percentage_optimizer.load_state_dict(percentage_checkpoint['optimizer_state_dict'])\n",
    "    binary_optimizer.load_state_dict(binary_checkpoint['optimizer_state_dict'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Train and evaluate PriceChangePrediction model\n",
    "train_and_evaluate(percentage_model, 'percentage_model', train_loader_pct, test_loader_pct, percentage_criterion, percentage_optimizer, epochs, device=device)\n",
    "\n",
    "# Train and evaluate PriceDirectionPrediction model\n",
    "train_and_evaluate(binary_model, 'binary_model', train_loader_binary, test_loader_binary, binary_criterion, binary_optimizer, epochs, device=device)\n",
    "\n",
    "# Get the output of binary_model for a random input\n",
    "random_input = torch.randn(1, 100, 1).to(device)  # Create a random tensor of shape (1, 100, 1)\n",
    "random_output = binary_model(random_input)  # Get the output\n",
    "\n",
    "print(random_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/1 | percentage_model Validation Loss: 0.0161349802\n",
    "Epoch 1/1 | binary_model Validation Loss: 0.6933783825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0007],\n",
      "         [0.0030],\n",
      "         [0.0033],\n",
      "         [0.0031],\n",
      "         [0.0030],\n",
      "         [0.0029],\n",
      "         [0.0029],\n",
      "         [0.0029],\n",
      "         [0.0029],\n",
      "         [0.0029],\n",
      "         [0.0030],\n",
      "         [0.0030],\n",
      "         [0.0030],\n",
      "         [0.0030],\n",
      "         [0.0030],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "random_input = torch.randn(1, 100, 1).to(device)  # Create a random tensor of shape (1, 100, 1)\n",
    "random_output = model1(random_input)  # Get the output\n",
    "\n",
    "print(random_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
