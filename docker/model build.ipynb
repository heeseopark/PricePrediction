{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader, Subset\n",
    "from datetime import datetime as dt, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from pandas import DataFrame as df\n",
    "import mplfinance as mpf\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "seed = 42  # choose any seed you prefer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, item, timespan, start_date_str, end_date_str):\n",
    "        self.directory = f'C:/Github/PricePrediction/csvfiles/{item}'\n",
    "        self.item = item\n",
    "        self.timespan = timespan\n",
    "        start_date = dt.strptime(start_date_str, '%Y-%m-%d').date()\n",
    "        end_date = dt.strptime(end_date_str, '%Y-%m-%d').date()\n",
    "        self.dates = [single_date.strftime(\"%Y-%m-%d\") for single_date in self.daterange(start_date, end_date)]\n",
    "        self.columns = [1, 4]  # Selecting open and close prices\n",
    "        self.filenames = self.get_filenames()\n",
    "\n",
    "    def daterange(self, start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days) + 1):\n",
    "            yield start_date + timedelta(n)\n",
    "\n",
    "    def get_filenames(self):\n",
    "        filenames = []\n",
    "        for date in self.dates:\n",
    "            filename = f\"{self.directory}/{self.item}-{self.timespan}-{date}.csv\"\n",
    "            if os.path.exists(filename):\n",
    "                filenames.append(filename)\n",
    "        return filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        df = pd.read_csv(filename, usecols=self.columns, header=None)\n",
    "        return torch.tensor(df.values, dtype=torch.float16)  # Return open and close prices\n",
    "\n",
    "def sliding_window_pct(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 400 + 1):  # Create windows of size window_size\n",
    "            window = tensor[i:i+400]\n",
    "            pct_change = (window[:, 1] - window[:, 0]) * 100 / window[:, 0]\n",
    "            windows.append(pct_change.half())  # Convert to float16\n",
    "    return torch.stack(windows)\n",
    "\n",
    "def sliding_window_binary(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 400 + 1):  # Create windows of size window_size\n",
    "            window = tensor[i:i+400]\n",
    "            binary_change = (window[:, 1] > window[:, 0]).float()  # Calculate the binary change\n",
    "            windows.append(binary_change.half())  # Convert to float16\n",
    "    return torch.stack(windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "train_dataset = PriceDataset('BTCUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "train_loader_pct = DataLoader(train_dataset, batch_size=1, collate_fn=sliding_window_pct, shuffle=False, drop_last=True)\n",
    "train_loader_binary = DataLoader(train_dataset, batch_size=1, collate_fn=sliding_window_binary, shuffle=False, drop_last=True)\n",
    "\n",
    "test_dataset = PriceDataset('ETHUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "test_loader_pct = DataLoader(test_dataset, batch_size=1, collate_fn=sliding_window_pct, shuffle=False, drop_last=True)\n",
    "test_loader_binary = DataLoader(test_dataset, batch_size=1, collate_fn=sliding_window_binary, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 791\n",
      "Test dataset size: 791\n",
      "Train dataloader size: 791\n",
      "Test dataloader size: 791\n",
      "Shape of the tensor output by train_dataset: torch.Size([1440, 2])\n",
      "Shape of the tensor output by train_loader: torch.Size([1041, 400])\n",
      "tensor([ 0.2837,  0.2122, -0.4939, -0.2128,  0.0000, -0.1421,  0.0712,  0.0711,\n",
      "         0.4976,  0.0000, -0.1415,  0.1416,  0.0000, -0.0707,  0.4951,  0.2815,\n",
      "         0.5615,  0.6274, -0.0693,  0.0693,  0.0693, -0.2078,  0.0694, -0.2080,\n",
      "         0.2781, -0.0693,  0.0000,  0.0000,  0.0000,  0.0000,  0.4854,  0.0000,\n",
      "         0.0690,  0.2759, -0.0688, -0.0688, -0.0689, -0.1379,  0.0690,  0.1381,\n",
      "        -0.0689,  0.0000,  0.0000, -0.1379, -0.1382,  0.0000, -0.1384,  0.0000,\n",
      "        -0.0693,  0.0693,  0.0000,  0.0693,  0.2771, -0.1381,  0.1383, -0.1381,\n",
      "        -0.1383,  0.0693, -0.0692,  0.0000,  0.1385, -0.1383, -0.0693,  0.0000,\n",
      "        -0.1385,  0.0000,  0.0000,  0.0000,  0.0694, -0.0693,  0.0000, -0.0695,\n",
      "         0.0695, -0.2084,  0.1392,  0.2085, -0.0693, -0.0694,  0.1389, -0.0693,\n",
      "        -0.4163, -0.0697,  0.2092,  0.2087,  0.1389, -0.1387, -0.0695,  0.1390,\n",
      "         0.0000, -0.0693,  0.3469,  0.4150, -0.2067, -0.0690, -0.1381, -0.1383,\n",
      "         0.1385, -0.2075, -0.0693,  0.0693, -0.0693,  0.0693,  0.0693, -0.0693,\n",
      "         0.1385,  0.1384, -0.1382,  0.1384,  0.1382, -0.1381,  0.0000,  0.0000,\n",
      "         0.0691, -0.0690, -0.1382, -0.2769, -0.0694,  0.2084, -0.0693,  0.0693,\n",
      "         0.0693, -0.0693,  0.2773,  0.0692, -0.0691,  0.0000,  0.0692,  0.0691,\n",
      "        -0.1381,  0.0000,  0.2075, -0.2070,  0.1383,  0.0690,  0.0690,  0.0690,\n",
      "        -0.2068, -0.0690, -0.0691,  0.0692,  0.2073,  0.0000,  0.0000,  0.1379,\n",
      "         0.4133,  0.0000,  0.2058,  0.0684, -0.2052, -0.0685,  0.2058,  0.0000,\n",
      "         0.0000,  0.0000, -0.2053,  0.0000, -0.0686,  0.0000, -0.0687,  0.0000,\n",
      "         0.0687, -0.1373,  0.0687, -0.0687, -0.0687, -0.1375,  0.0688,  0.0688,\n",
      "        -0.1375,  0.0688,  0.0688,  0.0000, -0.0687, -0.0688, -0.0688, -0.1377,\n",
      "         0.1379, -0.0688, -0.0689,  0.0690,  0.0690,  0.0689,  0.0688,  0.0688,\n",
      "        -0.2063, -0.2068,  0.0690, -0.2761,  0.2076, -0.0690,  0.0691,  0.0000,\n",
      "         0.0690, -0.0690,  0.1381,  0.0690,  0.0000,  0.0689,  0.0688, -0.0688,\n",
      "        -0.0688, -0.0688, -0.0689,  0.0000,  0.0690,  0.0689,  0.0688,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0688, -0.0688,  0.0689, -0.1377,  0.0690,\n",
      "        -0.0689, -0.0690, -0.0690,  0.0000, -0.0690, -0.0691,  0.0692,  0.0000,\n",
      "         0.0691, -0.2072,  0.1384,  0.0000,  0.0000,  0.0691,  0.0690,  0.0000,\n",
      "        -0.2070,  0.2075,  0.0690,  0.2759, -0.3440, -0.0690,  0.0690, -0.0690,\n",
      "         0.1381, -0.0689,  0.0690,  0.0689, -0.0688,  0.0000, -0.0689,  0.0690,\n",
      "         0.0000,  0.0000,  0.0000,  0.0689, -0.1377, -0.0690, -0.0690,  0.0690,\n",
      "        -0.1381, -0.0691, -0.0692, -0.2769, -0.0694, -0.0695, -0.1390,  0.1392,\n",
      "         0.0000, -0.0695,  0.0695,  0.1390,  0.0694,  0.0693, -0.1385,  0.0694,\n",
      "        -0.0693,  0.1388,  0.0000,  0.0000, -0.0693, -0.0694,  0.0695,  0.0000,\n",
      "        -0.0694, -0.0695,  0.1390,  0.2081,  0.1385,  0.0692,  0.1382,  0.0000,\n",
      "         0.0000,  0.0690,  0.4827, -0.2059, -0.0688,  0.0688, -0.2063,  0.0000,\n",
      "         0.0689, -0.0688,  0.0000,  0.0689, -0.1377,  0.0000,  0.1379, -0.2067,\n",
      "         0.0000, -0.0690,  0.0000,  0.0000,  0.0000,  0.0000,  0.1381, -0.2069,\n",
      "         0.0000,  0.0691, -0.0690,  0.0000, -0.1382,  0.0692,  0.0000, -0.1383,\n",
      "         0.0693, -0.0692,  0.0693,  0.0692,  0.0000, -0.0692,  0.0000,  0.0000,\n",
      "        -0.1384, -0.2771,  0.1390,  0.0694,  0.0693,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0693, -0.0693,  0.1388, -0.0693, -0.0693,  0.0694, -0.0693,  0.0694,\n",
      "        -0.0693,  0.0694, -0.0693, -0.0694, -0.0695,  0.1390,  0.0000,  0.0000,\n",
      "        -0.0694,  0.0695, -0.0694,  0.1389,  0.0693,  0.0000,  0.0693,  0.0000,\n",
      "         0.0000,  0.0000, -0.1385, -0.2080,  0.0695,  0.0000,  0.0694,  0.0000,\n",
      "         0.0693,  0.0693,  0.0000,  0.0693, -0.0692, -0.0693,  0.1385,  0.0000,\n",
      "        -0.0692,  0.1385, -0.0692,  0.0000, -0.0692, -0.1385,  0.0000,  0.0000,\n",
      "         0.0693,  0.0693,  0.0000,  0.0693, -0.0692,  0.0693,  0.0692, -0.1383,\n",
      "         0.0000, -0.0693, -0.1385, -0.2081,  0.0000,  0.0000,  0.0000, -0.2086],\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Size of the Dataset\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Test dataset size: {len(test_dataset)}')\n",
    "\n",
    "# Size of the DataLoader (i.e., number of batches)\n",
    "print(f'Train dataloader size: {len(train_loader_binary)}')\n",
    "print(f'Test dataloader size: {len(test_loader_binary)}')\n",
    "\n",
    "# Size of the tensor output by the Dataset\n",
    "sample_tensor = train_dataset[0]\n",
    "print(f'Shape of the tensor output by train_dataset: {sample_tensor.shape}')\n",
    "\n",
    "# Size of the tensor output by the DataLoader\n",
    "for batch in train_loader_binary:\n",
    "    print(f'Shape of the tensor output by train_loader: {batch.shape}')\n",
    "    break  # we break after the first batch\n",
    "\n",
    "first_batch = next(iter(train_loader_binary))\n",
    "\n",
    "first_batch = next(iter(train_loader_pct))\n",
    "print(first_batch[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceChangePrediction(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=100, output_dim=1, num_layers=4):\n",
    "        super(PriceChangePrediction, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout = 0.1)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        batch = batch.unsqueeze(-1).to(device).float()  # Adds an extra dimension and converts to float32\n",
    "        inputs = batch[:, :-1, :]\n",
    "        targets = batch[:, 1:, :]  # The targets are the next time-steps\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.unsqueeze(-1).to(device).float()  # Adds an extra dimension and converts to float32\n",
    "            inputs = batch[:, :-1, :]\n",
    "            targets = batch[:, 1:, :]  # The targets are the next time-steps\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)  # Return average loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, model_name, train_loader, test_loader, criterion, optimizer, epochs, device):\n",
    "    best_val_loss = float(1e-4)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} \\t {model_name} \\t Validation Loss: {val_loss:.5f}\")\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if val_loss < best_val_loss:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'models/{model_name}.pth')\n",
    "            best_val_loss = val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.57 GiB (GPU 0; 8.00 GiB total capacity; 3.45 GiB already allocated; 898.11 MiB free; 4.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[39m# Train and evaluate PriceChangePrediction model\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m train_and_evaluate(percentage_model, \u001b[39m'\u001b[39;49m\u001b[39mpercentage_model\u001b[39;49m\u001b[39m'\u001b[39;49m, train_loader_pct, test_loader_pct, percentage_criterion, percentage_optimizer, epochs, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     32\u001b[0m \u001b[39m# Train and evaluate PriceDirectionPrediction model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m train_and_evaluate(binary_model, \u001b[39m'\u001b[39m\u001b[39mbinary_model\u001b[39m\u001b[39m'\u001b[39m, train_loader_binary, test_loader_binary, binary_criterion, binary_optimizer, epochs, device\u001b[39m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[20], line 34\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, model_name, train_loader, test_loader, criterion, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m best_val_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m1e-4\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m---> 34\u001b[0m     train(model, train_loader, criterion, optimizer, device)\n\u001b[0;32m     35\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[0;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m Validation Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m targets \u001b[39m=\u001b[39m batch[:, \u001b[39m1\u001b[39m:, :]  \u001b[39m# The targets are the next time-steps\u001b[39;00m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 8\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m      9\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     10\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m, in \u001b[0;36mPriceChangePrediction.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m----> 8\u001b[0m     out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[0;32m      9\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out)\n\u001b[0;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.57 GiB (GPU 0; 8.00 GiB total capacity; 3.45 GiB already allocated; 898.11 MiB free; 4.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Create the models\n",
    "percentage_model = PriceChangePrediction().to(device)  # Use float32\n",
    "binary_model = PriceChangePrediction().to(device)  # Use float32\n",
    "\n",
    "# Define the loss functions\n",
    "percentage_criterion = nn.MSELoss()\n",
    "binary_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the optimizers\n",
    "percentage_optimizer = torch.optim.Adam(percentage_model.parameters(), lr=0.01)\n",
    "binary_optimizer = torch.optim.Adam(binary_model.parameters(), lr=0.01)\n",
    "\n",
    "try: \n",
    "    # Load the saved models and optimizers\n",
    "    percentage_checkpoint = torch.load('C:/Github/PricePrediction/docker/models/percentage_model.pth')\n",
    "    binary_checkpoint = torch.load('C:/Github/PricePrediction/docker/models/binary_model.pth')\n",
    "\n",
    "    percentage_model.load_state_dict(percentage_checkpoint['model_state_dict'])\n",
    "    binary_model.load_state_dict(binary_checkpoint['model_state_dict'])\n",
    "\n",
    "    percentage_optimizer.load_state_dict(percentage_checkpoint['optimizer_state_dict'])\n",
    "    binary_optimizer.load_state_dict(binary_checkpoint['optimizer_state_dict'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 1\n",
    "\n",
    "# Train and evaluate PriceChangePrediction model\n",
    "train_and_evaluate(percentage_model, 'percentage_model', train_loader_pct, test_loader_pct, percentage_criterion, percentage_optimizer, epochs, device=device)\n",
    "\n",
    "# Train and evaluate PriceDirectionPrediction model\n",
    "train_and_evaluate(binary_model, 'binary_model', train_loader_binary, test_loader_binary, binary_criterion, binary_optimizer, epochs, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in percentage_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", percentage_model.state_dict()[param_tensor].size())\n",
    "\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in percentage_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", percentage_optimizer.state_dict()[var_name])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/1 | percentage_model Validation Loss: 0.0161349802\n",
    "Epoch 1/1 | binary_model Validation Loss: 0.6933783825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.randn(1, 100, 1).to(device)  # Create a random tensor of shape (1, 100, 1)\n",
    "random_output = model1(random_input)  # Get the output\n",
    "\n",
    "print(random_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
