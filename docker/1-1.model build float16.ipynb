{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader, Subset\n",
    "from datetime import datetime as dt, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from pandas import DataFrame as df\n",
    "import mplfinance as mpf\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "seed = 42  # choose any seed you prefer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, item, timespan, start_date_str, end_date_str):\n",
    "        self.directory = f'C:/Github/PricePrediction/csvfiles/{item}'\n",
    "        self.item = item\n",
    "        self.timespan = timespan\n",
    "        start_date = dt.strptime(start_date_str, '%Y-%m-%d').date()\n",
    "        end_date = dt.strptime(end_date_str, '%Y-%m-%d').date()\n",
    "        self.dates = [single_date.strftime(\"%Y-%m-%d\") for single_date in self.daterange(start_date, end_date)]\n",
    "        self.columns = [1, 4]  # Selecting open and close prices\n",
    "        self.filenames = self.get_filenames()\n",
    "\n",
    "    def daterange(self, start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days) + 1):\n",
    "            yield start_date + timedelta(n)\n",
    "\n",
    "    def get_filenames(self):\n",
    "        filenames = []\n",
    "        for date in self.dates:\n",
    "            filename = f\"{self.directory}/{self.item}-{self.timespan}-{date}.csv\"\n",
    "            if os.path.exists(filename):\n",
    "                filenames.append(filename)\n",
    "        return filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        df = pd.read_csv(filename, usecols=self.columns, header=None)\n",
    "        return torch.tensor(df.values, dtype=torch.float16)  # Return open and close prices\n",
    "\n",
    "def sliding_window_pct(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 400 + 1):  # Create windows of size window_size\n",
    "            window = tensor[i:i+400]\n",
    "            pct_change = (window[:, 1] - window[:, 0]) * 100 / window[:, 0]\n",
    "            windows.append(pct_change.half())  # Convert to float16\n",
    "    return torch.stack(windows)\n",
    "\n",
    "def sliding_window_binary(batch):\n",
    "    windows = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - 400 + 1):  # Create windows of size window_size\n",
    "            window = tensor[i:i+400]\n",
    "            binary_change = (window[:, 1] > window[:, 0]).float()  # Calculate the binary change\n",
    "            windows.append(binary_change.half())  # Convert to float16\n",
    "    return torch.stack(windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "train_dataset = PriceDataset('BTCUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "train_loader_pct = DataLoader(train_dataset, batch_size=1, collate_fn=sliding_window_pct, shuffle=False, drop_last=True)\n",
    "train_loader_binary = DataLoader(train_dataset, batch_size=1, collate_fn=sliding_window_binary, shuffle=False, drop_last=True)\n",
    "\n",
    "test_dataset = PriceDataset('ETHUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "test_loader_pct = DataLoader(test_dataset, batch_size=1, collate_fn=sliding_window_pct, shuffle=False, drop_last=True)\n",
    "test_loader_binary = DataLoader(test_dataset, batch_size=1, collate_fn=sliding_window_binary, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 791\n",
      "Test dataset size: 791\n",
      "Train dataloader size: 791\n",
      "Test dataloader size: 791\n",
      "Shape of the tensor output by train_dataset: torch.Size([1440, 2])\n",
      "Shape of the tensor output by train_loader: <built-in method type of Tensor object at 0x00000278D6421CC0>\n",
      "tensor([ 0.2837,  0.2122, -0.4939, -0.2128,  0.0000, -0.1421,  0.0712,  0.0711,\n",
      "         0.4976,  0.0000, -0.1415,  0.1416,  0.0000, -0.0707,  0.4951,  0.2815,\n",
      "         0.5615,  0.6274, -0.0693,  0.0693,  0.0693, -0.2078,  0.0694, -0.2080,\n",
      "         0.2781, -0.0693,  0.0000,  0.0000,  0.0000,  0.0000,  0.4854,  0.0000,\n",
      "         0.0690,  0.2759, -0.0688, -0.0688, -0.0689, -0.1379,  0.0690,  0.1381,\n",
      "        -0.0689,  0.0000,  0.0000, -0.1379, -0.1382,  0.0000, -0.1384,  0.0000,\n",
      "        -0.0693,  0.0693,  0.0000,  0.0693,  0.2771, -0.1381,  0.1383, -0.1381,\n",
      "        -0.1383,  0.0693, -0.0692,  0.0000,  0.1385, -0.1383, -0.0693,  0.0000,\n",
      "        -0.1385,  0.0000,  0.0000,  0.0000,  0.0694, -0.0693,  0.0000, -0.0695,\n",
      "         0.0695, -0.2084,  0.1392,  0.2085, -0.0693, -0.0694,  0.1389, -0.0693,\n",
      "        -0.4163, -0.0697,  0.2092,  0.2087,  0.1389, -0.1387, -0.0695,  0.1390,\n",
      "         0.0000, -0.0693,  0.3469,  0.4150, -0.2067, -0.0690, -0.1381, -0.1383,\n",
      "         0.1385, -0.2075, -0.0693,  0.0693, -0.0693,  0.0693,  0.0693, -0.0693,\n",
      "         0.1385,  0.1384, -0.1382,  0.1384,  0.1382, -0.1381,  0.0000,  0.0000,\n",
      "         0.0691, -0.0690, -0.1382, -0.2769, -0.0694,  0.2084, -0.0693,  0.0693,\n",
      "         0.0693, -0.0693,  0.2773,  0.0692, -0.0691,  0.0000,  0.0692,  0.0691,\n",
      "        -0.1381,  0.0000,  0.2075, -0.2070,  0.1383,  0.0690,  0.0690,  0.0690,\n",
      "        -0.2068, -0.0690, -0.0691,  0.0692,  0.2073,  0.0000,  0.0000,  0.1379,\n",
      "         0.4133,  0.0000,  0.2058,  0.0684, -0.2052, -0.0685,  0.2058,  0.0000,\n",
      "         0.0000,  0.0000, -0.2053,  0.0000, -0.0686,  0.0000, -0.0687,  0.0000,\n",
      "         0.0687, -0.1373,  0.0687, -0.0687, -0.0687, -0.1375,  0.0688,  0.0688,\n",
      "        -0.1375,  0.0688,  0.0688,  0.0000, -0.0687, -0.0688, -0.0688, -0.1377,\n",
      "         0.1379, -0.0688, -0.0689,  0.0690,  0.0690,  0.0689,  0.0688,  0.0688,\n",
      "        -0.2063, -0.2068,  0.0690, -0.2761,  0.2076, -0.0690,  0.0691,  0.0000,\n",
      "         0.0690, -0.0690,  0.1381,  0.0690,  0.0000,  0.0689,  0.0688, -0.0688,\n",
      "        -0.0688, -0.0688, -0.0689,  0.0000,  0.0690,  0.0689,  0.0688,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0688, -0.0688,  0.0689, -0.1377,  0.0690,\n",
      "        -0.0689, -0.0690, -0.0690,  0.0000, -0.0690, -0.0691,  0.0692,  0.0000,\n",
      "         0.0691, -0.2072,  0.1384,  0.0000,  0.0000,  0.0691,  0.0690,  0.0000,\n",
      "        -0.2070,  0.2075,  0.0690,  0.2759, -0.3440, -0.0690,  0.0690, -0.0690,\n",
      "         0.1381, -0.0689,  0.0690,  0.0689, -0.0688,  0.0000, -0.0689,  0.0690,\n",
      "         0.0000,  0.0000,  0.0000,  0.0689, -0.1377, -0.0690, -0.0690,  0.0690,\n",
      "        -0.1381, -0.0691, -0.0692, -0.2769, -0.0694, -0.0695, -0.1390,  0.1392,\n",
      "         0.0000, -0.0695,  0.0695,  0.1390,  0.0694,  0.0693, -0.1385,  0.0694,\n",
      "        -0.0693,  0.1388,  0.0000,  0.0000, -0.0693, -0.0694,  0.0695,  0.0000,\n",
      "        -0.0694, -0.0695,  0.1390,  0.2081,  0.1385,  0.0692,  0.1382,  0.0000,\n",
      "         0.0000,  0.0690,  0.4827, -0.2059, -0.0688,  0.0688, -0.2063,  0.0000,\n",
      "         0.0689, -0.0688,  0.0000,  0.0689, -0.1377,  0.0000,  0.1379, -0.2067,\n",
      "         0.0000, -0.0690,  0.0000,  0.0000,  0.0000,  0.0000,  0.1381, -0.2069,\n",
      "         0.0000,  0.0691, -0.0690,  0.0000, -0.1382,  0.0692,  0.0000, -0.1383,\n",
      "         0.0693, -0.0692,  0.0693,  0.0692,  0.0000, -0.0692,  0.0000,  0.0000,\n",
      "        -0.1384, -0.2771,  0.1390,  0.0694,  0.0693,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0693, -0.0693,  0.1388, -0.0693, -0.0693,  0.0694, -0.0693,  0.0694,\n",
      "        -0.0693,  0.0694, -0.0693, -0.0694, -0.0695,  0.1390,  0.0000,  0.0000,\n",
      "        -0.0694,  0.0695, -0.0694,  0.1389,  0.0693,  0.0000,  0.0693,  0.0000,\n",
      "         0.0000,  0.0000, -0.1385, -0.2080,  0.0695,  0.0000,  0.0694,  0.0000,\n",
      "         0.0693,  0.0693,  0.0000,  0.0693, -0.0692, -0.0693,  0.1385,  0.0000,\n",
      "        -0.0692,  0.1385, -0.0692,  0.0000, -0.0692, -0.1385,  0.0000,  0.0000,\n",
      "         0.0693,  0.0693,  0.0000,  0.0693, -0.0692,  0.0693,  0.0692, -0.1383,\n",
      "         0.0000, -0.0693, -0.1385, -0.2081,  0.0000,  0.0000,  0.0000, -0.2086],\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Size of the Dataset\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Test dataset size: {len(test_dataset)}')\n",
    "\n",
    "# Size of the DataLoader (i.e., number of batches)\n",
    "print(f'Train dataloader size: {len(train_loader_binary)}')\n",
    "print(f'Test dataloader size: {len(test_loader_binary)}')\n",
    "\n",
    "# Size of the tensor output by the Dataset\n",
    "sample_tensor = train_dataset[0]\n",
    "print(f'Shape of the tensor output by train_dataset: {sample_tensor.shape}')\n",
    "\n",
    "# Size of the tensor output by the DataLoader\n",
    "for batch in train_loader_binary:\n",
    "    print(f'Shape of the tensor output by train_loader: {batch.type}')\n",
    "    break  # we break after the first batch\n",
    "\n",
    "first_batch = next(iter(train_loader_binary))\n",
    "\n",
    "first_batch = next(iter(train_loader_pct))\n",
    "print(first_batch[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceChangePrediction(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=100, output_dim=1, num_layers=4):\n",
    "        super(PriceChangePrediction, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout = 0.1)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Initialize the hidden state\n",
    "        self.hidden = (torch.zeros(num_layers, 1, hidden_dim),\n",
    "                       torch.zeros(num_layers, 1, hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()  # Convert input data to float32\n",
    "        out, self.hidden = self.lstm(x, self.hidden)  # Pass the hidden state to the LSTM\n",
    "        out = self.fc(out)\n",
    "        return out.half()  # Convert output back to float16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceChangePrediction(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=100, output_dim=1, num_layers=4, device='cpu'):\n",
    "        super(PriceChangePrediction, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch_size, hidden_size)\n",
    "        return (torch.zeros(self.num_layers, 1, self.hidden_dim).to(self.device),\n",
    "                torch.zeros(self.num_layers, 1, self.hidden_dim).to(self.device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()  # Convert input data to float32\n",
    "        out, self.hidden = self.lstm(x, self.hidden)\n",
    "        out = self.fc(out)\n",
    "        return out.half()  # Convert output back to float16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor Shape: torch.Size([1, 100, 1])\n",
      "Input Tensor Type: torch.float16\n",
      "Output Tensor Shape: torch.Size([1, 100, 1])\n",
      "Output Tensor Type: torch.float16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the model\n",
    "model = PriceChangePrediction()\n",
    "\n",
    "# Create a sample input tensor of length 100\n",
    "# Assume we are working with batch size 1 and each data point is 1-dimensional\n",
    "input_tensor = torch.randn(1, 100, 1).half()  # Create a half precision tensor\n",
    "\n",
    "print(f\"Input Tensor Shape: {input_tensor.shape}\")\n",
    "print(f\"Input Tensor Type: {input_tensor.dtype}\")\n",
    "\n",
    "# Feed the input tensor through the model\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(f\"Output Tensor Shape: {output_tensor.shape}\")\n",
    "print(f\"Output Tensor Type: {output_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        model.hidden = tuple([each.data for each in model.hidden])  # Detach hidden state from its history\n",
    "        batch = batch.unsqueeze(-1).to(device).float()  # Adds an extra dimension and converts to float32\n",
    "        inputs = batch[:, :-1, :].half()  # Convert inputs to float16\n",
    "        targets = batch[:, 1:, :]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).float()  # Convert outputs back to float32 for loss computation\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.unsqueeze(-1).to(device).float()  # Adds an extra dimension and converts to float32\n",
    "            inputs = batch[:, :-1, :].half()  # Convert inputs to float16\n",
    "            targets = batch[:, 1:, :]\n",
    "            outputs = model(inputs).float()  # Convert outputs back to float32 for loss computation\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)  # Return average loss\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs, device):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} \\t {str(model)} \\t Validation Loss: {val_loss:.5f}\")\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if val_loss < best_val_loss:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'models/{str(model)}.pth')\n",
    "            best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        batch = batch.unsqueeze(-1).to(device).float()  # Adds an extra dimension and converts to float32\n",
    "        inputs = batch[:, :-1, :].half()  # Convert inputs to float16\n",
    "        targets = batch[:, 1:, :]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).float()  # Convert outputs back to float32 for loss computation\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.unsqueeze(-1).to(device).float()  # Adds an extra dimension and converts to float32\n",
    "            inputs = batch[:, :-1, :].half()  # Convert inputs to float16\n",
    "            targets = batch[:, 1:, :]\n",
    "            outputs = model(inputs).float()  # Convert outputs back to float32 for loss computation\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)  # Return average loss\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs, device):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} \\t {str(model)} \\t Validation Loss: {val_loss:.5f}\")\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if val_loss < best_val_loss:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'models/{str(model)}.pth')\n",
    "            best_val_loss = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (4, 1041, 100), got [4, 1, 100]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[39m# Train and evaluate PriceChangePrediction model\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m train_and_evaluate(percentage_model, train_loader_pct, test_loader_pct, percentage_criterion, percentage_optimizer, epochs, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     32\u001b[0m \u001b[39m# Train and evaluate PriceDirectionPrediction model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m train_and_evaluate(binary_model, train_loader_binary, test_loader_binary, binary_criterion, binary_optimizer, epochs, device\u001b[39m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[150], line 32\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_loader, test_loader, criterion, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m best_val_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m---> 32\u001b[0m     train(model, train_loader, criterion, optimizer, device)\n\u001b[0;32m     33\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[0;32m     34\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(model)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m Validation Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[150], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m targets \u001b[39m=\u001b[39m batch[:, \u001b[39m1\u001b[39m:, :]\n\u001b[0;32m      8\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\u001b[39m.\u001b[39mfloat()  \u001b[39m# Convert outputs back to float32 for loss computation\u001b[39;00m\n\u001b[0;32m     10\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     11\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[148], line 20\u001b[0m, in \u001b[0;36mPriceChangePrediction.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     19\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mfloat()  \u001b[39m# Convert input data to float32\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden)\n\u001b[0;32m     21\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out)\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39mhalf()\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:810\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    806\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m--> 810\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:731\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    726\u001b[0m                        \u001b[39minput\u001b[39m: Tensor,\n\u001b[0;32m    727\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    728\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    729\u001b[0m                        ):\n\u001b[0;32m    730\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_input(\u001b[39minput\u001b[39m, batch_sizes)\n\u001b[1;32m--> 731\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_hidden_size(hidden[\u001b[39m0\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_expected_hidden_size(\u001b[39minput\u001b[39;49m, batch_sizes),\n\u001b[0;32m    732\u001b[0m                            \u001b[39m'\u001b[39;49m\u001b[39mExpected hidden[0] size \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m, got \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    733\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_cell_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[0;32m    734\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[1] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:239\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_hidden_size\u001b[39m(\u001b[39mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m],\n\u001b[0;32m    237\u001b[0m                       msg: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mExpected hidden size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m hx\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m expected_hidden_size:\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(expected_hidden_size, \u001b[39mlist\u001b[39m(hx\u001b[39m.\u001b[39msize())))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (4, 1041, 100), got [4, 1, 100]"
     ]
    }
   ],
   "source": [
    "# Create the models\n",
    "percentage_model = PriceChangePrediction().to(device)\n",
    "binary_model = PriceChangePrediction().to(device)\n",
    "\n",
    "# Define the loss functions\n",
    "percentage_criterion = nn.MSELoss()\n",
    "binary_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the optimizers\n",
    "percentage_optimizer = torch.optim.Adam(percentage_model.parameters(), lr=0.01)\n",
    "binary_optimizer = torch.optim.Adam(binary_model.parameters(), lr=0.01)\n",
    "\n",
    "try: \n",
    "    # Load the saved models and optimizers\n",
    "    percentage_checkpoint = torch.load('C:/Github/PricePrediction/docker/models/percentage_model.pth')\n",
    "    binary_checkpoint = torch.load('C:/Github/PricePrediction/docker/models/binary_model.pth')\n",
    "\n",
    "    percentage_model.load_state_dict(percentage_checkpoint['model_state_dict'])\n",
    "    binary_model.load_state_dict(binary_checkpoint['model_state_dict'])\n",
    "\n",
    "    percentage_optimizer.load_state_dict(percentage_checkpoint['optimizer_state_dict'])\n",
    "    binary_optimizer.load_state_dict(binary_checkpoint['optimizer_state_dict'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 1\n",
    "\n",
    "# Train and evaluate PriceChangePrediction model\n",
    "train_and_evaluate(percentage_model, train_loader_pct, test_loader_pct, percentage_criterion, percentage_optimizer, epochs, device=device)\n",
    "\n",
    "# Train and evaluate PriceDirectionPrediction model\n",
    "train_and_evaluate(binary_model, train_loader_binary, test_loader_binary, binary_criterion, binary_optimizer, epochs, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in percentage_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", percentage_model.state_dict()[param_tensor].size())\n",
    "\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in percentage_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", percentage_optimizer.state_dict()[var_name])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/1 | percentage_model Validation Loss: 0.0161349802\n",
    "Epoch 1/1 | binary_model Validation Loss: 0.6933783825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0729],\n",
      "         [0.0561],\n",
      "         [0.0472],\n",
      "         [0.0436],\n",
      "         [0.0407],\n",
      "         [0.0386],\n",
      "         [0.0382],\n",
      "         [0.0382],\n",
      "         [0.0356],\n",
      "         [0.0367],\n",
      "         [0.0370],\n",
      "         [0.0372],\n",
      "         [0.0346],\n",
      "         [0.0373],\n",
      "         [0.0371],\n",
      "         [0.0377],\n",
      "         [0.0386],\n",
      "         [0.0371],\n",
      "         [0.0379],\n",
      "         [0.0375],\n",
      "         [0.0371],\n",
      "         [0.0378],\n",
      "         [0.0384],\n",
      "         [0.0353],\n",
      "         [0.0360],\n",
      "         [0.0371],\n",
      "         [0.0383],\n",
      "         [0.0378],\n",
      "         [0.0386],\n",
      "         [0.0372],\n",
      "         [0.0379],\n",
      "         [0.0399],\n",
      "         [0.0409],\n",
      "         [0.0395],\n",
      "         [0.0389],\n",
      "         [0.0381],\n",
      "         [0.0388],\n",
      "         [0.0385],\n",
      "         [0.0391],\n",
      "         [0.0388],\n",
      "         [0.0371],\n",
      "         [0.0370],\n",
      "         [0.0368],\n",
      "         [0.0385],\n",
      "         [0.0380],\n",
      "         [0.0362],\n",
      "         [0.0368],\n",
      "         [0.0392],\n",
      "         [0.0367],\n",
      "         [0.0359],\n",
      "         [0.0370],\n",
      "         [0.0382],\n",
      "         [0.0385],\n",
      "         [0.0382],\n",
      "         [0.0387],\n",
      "         [0.0377],\n",
      "         [0.0397],\n",
      "         [0.0383],\n",
      "         [0.0372],\n",
      "         [0.0369],\n",
      "         [0.0361],\n",
      "         [0.0373],\n",
      "         [0.0384],\n",
      "         [0.0388],\n",
      "         [0.0392],\n",
      "         [0.0363],\n",
      "         [0.0363],\n",
      "         [0.0385],\n",
      "         [0.0388],\n",
      "         [0.0374],\n",
      "         [0.0386],\n",
      "         [0.0400],\n",
      "         [0.0395],\n",
      "         [0.0388],\n",
      "         [0.0371],\n",
      "         [0.0383],\n",
      "         [0.0368],\n",
      "         [0.0357],\n",
      "         [0.0357],\n",
      "         [0.0375],\n",
      "         [0.0382],\n",
      "         [0.0363],\n",
      "         [0.0362],\n",
      "         [0.0361],\n",
      "         [0.0375],\n",
      "         [0.0392],\n",
      "         [0.0372],\n",
      "         [0.0372],\n",
      "         [0.0378],\n",
      "         [0.0370],\n",
      "         [0.0384],\n",
      "         [0.0376],\n",
      "         [0.0376],\n",
      "         [0.0373],\n",
      "         [0.0366],\n",
      "         [0.0383],\n",
      "         [0.0387],\n",
      "         [0.0371],\n",
      "         [0.0386],\n",
      "         [0.0383]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "random_input = torch.randn(1, 100, 1).to(device)  # Create a random tensor of shape (1, 100, 1)\n",
    "random_output = percentage_model(random_input.half())  # Get the output\n",
    "\n",
    "print(random_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
